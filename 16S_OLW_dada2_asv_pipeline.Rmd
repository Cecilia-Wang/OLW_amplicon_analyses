---
title: "OLW_16S_1"
author: "Cecilia"
date: "9/3/2019"
output: html_document
editor_options: 
  chunk_output_type: console
---
# the complete dada2 pipeline for amplicon analyses with ASVs output

```{r load libraries}

library(dada2); packageVersion("dada2")
#[1] ‘1.12.1’
library(phyloseq); packageVersion("phyloseq")
## [1] '1.28.0'
library(Biostrings); packageVersion("Biostrings")
## [1] '2.52.0'
library(ggplot2); packageVersion("ggplot2")
## [1] ‘3.2.1’
library(dplyr); packageVersion("dplyr")
## [1] ‘0.8.3’
library(scales); packageVersion("scales")
## [1] ‘1.0.0’

```


```{r load datasets}

# change the path directory to local directory
path<-"file_1_path"
list.files(path)
path2<-"file2_path"
list.files(path2)


# Sample 85 and 94 are removed due to less than 30 reads in total


# Forward and reverse fastq filenames have format: SAMPLENAME_L001_R1_001.fastq and SAMPLENAME_L002_R2_001.fastq
fnFs1 <- sort(list.files(path, pattern="_L001_R1_001.fastq.gz", full.names = TRUE))
fnRs1 <- sort(list.files(path, pattern="_L001_R2_001.fastq.gz", full.names = TRUE))
fnFs2 <- sort(list.files(path2, pattern="_L001_R1_001.fastq.gz", full.names = TRUE))
fnRs2 <- sort(list.files(path2, pattern="_L001_R2_001.fastq.gz", full.names = TRUE))
fnFs<-c(fnFs1,fnFs2)
fnRs<-c(fnRs1,fnRs2)

# Extract sample names, assuming filenames have format: SAMPLENAME_XXX.fastq
sample.names1 <- paste0(sapply(strsplit(basename(fnFs1), "_"), `[`, 1),"_",sapply(strsplit(basename(fnFs1), "_"), `[`, 2))
sample.names2 <- paste0(sapply(strsplit(basename(fnFs2), "_"), `[`, 1),"_",sapply(strsplit(basename(fnFs2), "_"), `[`, 2))
sample.names<-c(sample.names1,sample.names2)
```


```{r quality visual, eval=FALSE, include=FALSE}
# Visualisation of read qualities
# for reverse reads, a dramatic drop on quality @ about cycle 20, not sure what caused that. 
plotQualityProfile(fnFs1[1:6])
plotQualityProfile(fnRs1[1:6])
plotQualityProfile(fnFs2[1:6])
plotQualityProfile(fnRs2[1:6])




```

```{r datasets QC and filterations}
# Place filtered files in filtered/ subdirectory
# filter 16S results from file_1 and file_2 will, then put into the same folder for further analyses 
filtFs1 <- file.path(path, "filtered", paste0(sample.names1, "_F_filt.fastq.gz"))
filtRs1 <- file.path(path, "filtered", paste0(sample.names1, "_R_filt.fastq.gz"))
filtFs2 <- file.path(path, "filtered", paste0(sample.names2, "_F_filt.fastq.gz"))
filtRs2 <- file.path(path, "filtered", paste0(sample.names2, "_R_filt.fastq.gz"))

# file name combine
filtFs<-c(filtFs1,filtFs2)
filtRs<-c(filtRs1,filtRs2)
names(filtFs) <- sample.names



# filter and trim the reads with a maximum number of 2 errors 
out1 <- filterAndTrim(fnFs1, filtFs1, fnRs1, filtRs1,
              maxN=0, maxEE=c(2,2), truncQ=2, rm.phix=TRUE,
              compress=TRUE, multithread=TRUE) # On Windows set multithread=FALSE
out1

out2 <- filterAndTrim(fnFs2, filtFs2, fnRs2, filtRs2,
              maxN=0, maxEE=c(2,2), truncQ=2, rm.phix=TRUE,
              compress=TRUE, multithread=TRUE) # On Windows set multithread=FALSE
# list out number of reads before and after filter+trim
out2
out<-rbind(out1,out2)

# estimate error rate for the filtered datasets
errF <- learnErrors(filtFs, multithread=TRUE)
errR <- learnErrors(filtRs, multithread=TRUE)
# 
plotErrors(errF, nominalQ=TRUE)
plotErrors(errR, nominalQ=TRUE)

```


```{r}
dadaFs <- dada(filtFs, err=errF, multithread=TRUE)
dadaRs <- dada(filtRs, err=errR, multithread=TRUE)
dadaFs[[1]]
mergers <- mergePairs(dadaFs, filtFs, dadaRs, filtRs, verbose=TRUE)
# Inspect the merger data.frame from the first sample
head(mergers[[1]])

# construct an amplicon sequence variant table (ASV) table
seqtab <- makeSequenceTable(mergers)
dim(seqtab)
# Inspect distribution of sequence lengths
table(nchar(getSequences(seqtab)))

##Remove chimeras
seqtab.nochim <- removeBimeraDenovo(seqtab, method="consensus", multithread=TRUE, verbose=TRUE)
dim(seqtab.nochim)
sum(seqtab.nochim)/sum(seqtab)

# Change on number of reads through pipeline
getN <- function(x) sum(getUniques(x))
track <- cbind(out, sapply(dadaFs, getN), sapply(dadaRs, getN), sapply(mergers, getN), rowSums(seqtab.nochim))
# If processing a single sample, remove the sapply calls: e.g. replace sapply(dadaFs, getN) with getN(dadaFs)
colnames(track) <- c("input", "filtered", "denoisedF", "denoisedR", "merged", "nonchim")
rownames(track) <- sample.names
head(track)

# Assign taxonomy for ASVs. (silva database is downloaded from https://benjjneb.github.io/dada2/training.html)

taxa <- assignTaxonomy(seqtab.nochim, "database/silva_nr_v132_train_set.fa.gz", multithread=TRUE)
taxa.print <- taxa 
rownames(taxa.print) <- NULL # Removing sequence rownames for display only
head(taxa.print)




```

```{r import metadata and build phyloseq}

# modify sample names to match with the metadata
meta<-read.csv("metadata.csv")
meta$SampleName<-as.character(meta$SampleName)
meta$Alternative.name<-as.character(meta$Alternative.name)
meta$Alternative.name<-ifelse(meta$Alternative.name=="", meta$SampleName,meta$Alternative.name)
meta<-subset(meta, !is.na(meta$SampleID))
Plate1_sample99<-c(99, "F17_480", "F17_480", "Faecal",	"RG 150N", "515rcbc35",	"GAGATACAGTTC")
meta<-rbind(meta, Plate1_sample99)


# build the metadata for phyloseq
samples.out <- rownames(seqtab.nochim)
Sample_ID <- as.numeric(sapply(strsplit(basename(samples.out), "_"), `[`, 1))
samdf<- data.frame(meta[match(Sample_ID,meta$SampleID),],Sample_uni=samples.out, stringsAsFactors = FALSE)
samdf[samdf$Sample_uni=="99_S23",]<-c("99", "F17_480", "F17_480", "Faecal",	"RG 150N", "515rcbc35",	"GAGATACAGTTC","99_S23")
samdf[] <- lapply(samdf, as.character)
rownames(samdf) <- samples.out
write.csv(samdf, "ASV_meta_complete.csv",row.names = FALSE)

ps_16S <- phyloseq(otu_table(seqtab.nochim, taxa_are_rows=FALSE), 
               sample_data(samdf), 
               tax_table(taxa))
dna <- Biostrings::DNAStringSet(taxa_names(ps_16S))
names(dna) <- taxa_names(ps_16S)
ps_16S <- merge_phyloseq(ps_16S, dna)
taxa_names(ps_16S) <- paste0("ASV", seq(ntaxa(ps_16S)))
ps_16S

```



```{r list all packages used for this script and the version}
sessionInfo()

```